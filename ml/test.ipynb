{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Notebook\n",
    "For testing models to be used to identify duplication resume form questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import FastText\n",
    "from gensim.test.utils import common_texts\n",
    "import gensim.downloader\n",
    "from nltk.tokenize.regexp import regexp_tokenize\n",
    "from nltk import word_tokenize\n",
    "import pandas as pd\n",
    "import swifter\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import euclidean, cosine\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, log_loss\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.downloader.load('fasttext-wiki-news-subwords-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmodel = SentenceTransformer('quora-distilbert-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sw_set = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./data/train.csv')\n",
    "sample_df = train_df.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = str.maketrans('/', ' ', '\\'[\\\\]^_`{|}~\"#$%&()*+,-:;<=>@?.!' + string.digits)\n",
    "def clean_chars(text):\n",
    "    text = text.replace('\\t', ' ')\n",
    "    text = text.translate(table)\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = clean_chars(text)\n",
    "    words = (x.lower() for x in word_tokenize(text))\n",
    "    words = [word for word in words if word not in sw_set]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['good', 'geologist']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text('How can I be a good geologist?')\n",
    "# kind of aggressive, but good for our use case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = [\n",
    "    'Are you authorized to work in the United States without Visa Sponsorship or EAD?',\n",
    "    'Will you now, or in the future, require sponsorship for employment Visa status (e.g., H-1B, visa status)?',\n",
    "    'Will you now or in the future require sponsorship for employment visa status (e.g. H1B status)?',\n",
    "    'How did you hear about this job?',\n",
    "    'What was your favorite technical question that you were asked during an interview?',\n",
    "    'Why are you interested in working at Karat?',\n",
    "    'Are you legally eligible to work in the U.S.?',\n",
    "    'Will you now or in the future require visa sponsorship for employment at the Karat?',\n",
    "    'First Name',\n",
    "    'Last Name',\n",
    "    'Show us your work! Please share any links to personal, open source projects or code samples. The team would love to see your work.'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================\n",
      "Are you authorized to work in the United States without Visa Sponsorship or EAD? vs Will you now, or in the future, require sponsorship for employment Visa status (e.g., H-1B, visa status)? : 0.14285714285714285\n",
      "Are you authorized to work in the United States without Visa Sponsorship or EAD? vs Will you now or in the future require sponsorship for employment visa status (e.g. H1B status)? : 0.14285714285714285\n",
      "Are you authorized to work in the United States without Visa Sponsorship or EAD? vs How did you hear about this job? : 0.0\n",
      "Are you authorized to work in the United States without Visa Sponsorship or EAD? vs What was your favorite technical question that you were asked during an interview? : 0.0\n",
      "Are you authorized to work in the United States without Visa Sponsorship or EAD? vs Why are you interested in working at Karat? : 0.0\n",
      "Are you authorized to work in the United States without Visa Sponsorship or EAD? vs Are you legally eligible to work in the U.S.? : 0.09090909090909091\n",
      "Are you authorized to work in the United States without Visa Sponsorship or EAD? vs Will you now or in the future require visa sponsorship for employment at the Karat? : 0.16666666666666666\n",
      "Are you authorized to work in the United States without Visa Sponsorship or EAD? vs First Name : 0.0\n",
      "Are you authorized to work in the United States without Visa Sponsorship or EAD? vs Last Name : 0.0\n",
      "Are you authorized to work in the United States without Visa Sponsorship or EAD? vs Show us your work! Please share any links to personal, open source projects or code samples. The team would love to see your work. : 0.043478260869565216\n",
      "=========================\n",
      "Will you now, or in the future, require sponsorship for employment Visa status (e.g., H-1B, visa status)? vs Will you now or in the future require sponsorship for employment visa status (e.g. H1B status)? : 1.0\n",
      "Will you now, or in the future, require sponsorship for employment Visa status (e.g., H-1B, visa status)? vs How did you hear about this job? : 0.0\n",
      "Will you now, or in the future, require sponsorship for employment Visa status (e.g., H-1B, visa status)? vs What was your favorite technical question that you were asked during an interview? : 0.0\n",
      "Will you now, or in the future, require sponsorship for employment Visa status (e.g., H-1B, visa status)? vs Why are you interested in working at Karat? : 0.0\n",
      "Will you now, or in the future, require sponsorship for employment Visa status (e.g., H-1B, visa status)? vs Are you legally eligible to work in the U.S.? : 0.0\n",
      "Will you now, or in the future, require sponsorship for employment Visa status (e.g., H-1B, visa status)? vs Will you now or in the future require visa sponsorship for employment at the Karat? : 0.5555555555555556\n",
      "Will you now, or in the future, require sponsorship for employment Visa status (e.g., H-1B, visa status)? vs First Name : 0.0\n",
      "Will you now, or in the future, require sponsorship for employment Visa status (e.g., H-1B, visa status)? vs Last Name : 0.0\n",
      "Will you now, or in the future, require sponsorship for employment Visa status (e.g., H-1B, visa status)? vs Show us your work! Please share any links to personal, open source projects or code samples. The team would love to see your work. : 0.0\n",
      "=========================\n",
      "Will you now or in the future require sponsorship for employment visa status (e.g. H1B status)? vs How did you hear about this job? : 0.0\n",
      "Will you now or in the future require sponsorship for employment visa status (e.g. H1B status)? vs What was your favorite technical question that you were asked during an interview? : 0.0\n",
      "Will you now or in the future require sponsorship for employment visa status (e.g. H1B status)? vs Why are you interested in working at Karat? : 0.0\n",
      "Will you now or in the future require sponsorship for employment visa status (e.g. H1B status)? vs Are you legally eligible to work in the U.S.? : 0.0\n",
      "Will you now or in the future require sponsorship for employment visa status (e.g. H1B status)? vs Will you now or in the future require visa sponsorship for employment at the Karat? : 0.5555555555555556\n",
      "Will you now or in the future require sponsorship for employment visa status (e.g. H1B status)? vs First Name : 0.0\n",
      "Will you now or in the future require sponsorship for employment visa status (e.g. H1B status)? vs Last Name : 0.0\n",
      "Will you now or in the future require sponsorship for employment visa status (e.g. H1B status)? vs Show us your work! Please share any links to personal, open source projects or code samples. The team would love to see your work. : 0.0\n",
      "=========================\n",
      "How did you hear about this job? vs What was your favorite technical question that you were asked during an interview? : 0.0\n",
      "How did you hear about this job? vs Why are you interested in working at Karat? : 0.0\n",
      "How did you hear about this job? vs Are you legally eligible to work in the U.S.? : 0.0\n",
      "How did you hear about this job? vs Will you now or in the future require visa sponsorship for employment at the Karat? : 0.0\n",
      "How did you hear about this job? vs First Name : 0.0\n",
      "How did you hear about this job? vs Last Name : 0.0\n",
      "How did you hear about this job? vs Show us your work! Please share any links to personal, open source projects or code samples. The team would love to see your work. : 0.0\n",
      "=========================\n",
      "What was your favorite technical question that you were asked during an interview? vs Why are you interested in working at Karat? : 0.0\n",
      "What was your favorite technical question that you were asked during an interview? vs Are you legally eligible to work in the U.S.? : 0.0\n",
      "What was your favorite technical question that you were asked during an interview? vs Will you now or in the future require visa sponsorship for employment at the Karat? : 0.0\n",
      "What was your favorite technical question that you were asked during an interview? vs First Name : 0.0\n",
      "What was your favorite technical question that you were asked during an interview? vs Last Name : 0.0\n",
      "What was your favorite technical question that you were asked during an interview? vs Show us your work! Please share any links to personal, open source projects or code samples. The team would love to see your work. : 0.0\n",
      "=========================\n",
      "Why are you interested in working at Karat? vs Are you legally eligible to work in the U.S.? : 0.0\n",
      "Why are you interested in working at Karat? vs Will you now or in the future require visa sponsorship for employment at the Karat? : 0.125\n",
      "Why are you interested in working at Karat? vs First Name : 0.0\n",
      "Why are you interested in working at Karat? vs Last Name : 0.0\n",
      "Why are you interested in working at Karat? vs Show us your work! Please share any links to personal, open source projects or code samples. The team would love to see your work. : 0.0\n",
      "=========================\n",
      "Are you legally eligible to work in the U.S.? vs Will you now or in the future require visa sponsorship for employment at the Karat? : 0.0\n",
      "Are you legally eligible to work in the U.S.? vs First Name : 0.0\n",
      "Are you legally eligible to work in the U.S.? vs Last Name : 0.0\n",
      "Are you legally eligible to work in the U.S.? vs Show us your work! Please share any links to personal, open source projects or code samples. The team would love to see your work. : 0.1111111111111111\n",
      "=========================\n",
      "Will you now or in the future require visa sponsorship for employment at the Karat? vs First Name : 0.0\n",
      "Will you now or in the future require visa sponsorship for employment at the Karat? vs Last Name : 0.0\n",
      "Will you now or in the future require visa sponsorship for employment at the Karat? vs Show us your work! Please share any links to personal, open source projects or code samples. The team would love to see your work. : 0.0\n",
      "=========================\n",
      "First Name vs Last Name : 0.3333333333333333\n",
      "First Name vs Show us your work! Please share any links to personal, open source projects or code samples. The team would love to see your work. : 0.0\n",
      "=========================\n",
      "Last Name vs Show us your work! Please share any links to personal, open source projects or code samples. The team would love to see your work. : 0.0\n",
      "=========================\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(ss)):\n",
    "    print('='*25)\n",
    "    for j in range(i+1, len(ss)):\n",
    "        if i == j:\n",
    "            continue\n",
    "        print(ss[i], 'vs', ss[j], ':', jaccard(clean_text(ss[i]), clean_text(ss[j])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = clean_text('Are you authorized to work in the United States without Visa Sponsorship or EAD?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2 = clean_text('Will you now, or in the future, require sponsorship for employment Visa status (e.g., H-1B, visa status)?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "w3 = clean_text('Will you now or in the future require sponsorship for employment visa status (e.g. H1B status)?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "w4 = clean_text('How did you hear about this job?')\n",
    "# f4 = extract_feats(w4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14285714285714285"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jaccard(w2, w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = extract_feats(w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f2 = extract_feats(w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f3 = extract_feats(w3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testSamp = feat_vector(f1, f2)\n",
    "bst.predict(testSamp.reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testSamp = feat_vector(f1, f3)\n",
    "bst.predict(testSamp.reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testSamp = feat_vector(f1, f4)\n",
    "bst.predict(testSamp.reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testSamp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "try bag of word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words='english', max_features=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = vectorizer.fit_transform(chain(sample_df.question1, sample_df.question2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3000)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(vectorizer.transform([ss[0]]) - vectorizer.transform([ss[1]])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.68128587, 0.31871413]])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.predict_proba(np.abs(vectorizer.transform([ss[1]]) - vectorizer.transform([ss[2]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.predict(np.abs(vectorizer.transform([ss[1]]) - vectorizer.transform([ss[2]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-152-a381a184eda1>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sample_df['q1_words'] = sample_df.question1.apply(clean_text)\n"
     ]
    }
   ],
   "source": [
    "sample_df['q1_words'] = sample_df.question1.apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-153-fec924e97a31>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sample_df['q2_words'] = sample_df.question2.apply(clean_text)\n"
     ]
    }
   ],
   "source": [
    "sample_df['q2_words'] = sample_df.question2.apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard(a, b):\n",
    "    a_s = set(a)\n",
    "    b_s = set(b)\n",
    "    if len(a_s) == 0 and len(b_s) == 0:\n",
    "        return 1\n",
    "    return len(a_s & b_s) / len(a_s | b_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "jacc = []\n",
    "for (a, b) in zip(sample_df.q1_words, sample_df.q2_words):\n",
    "    jacc.append(jaccard(a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.83333333],\n",
       "       [0.22222222],\n",
       "       [0.22222222],\n",
       "       ...,\n",
       "       [0.33333333],\n",
       "       [0.        ],\n",
       "       [1.        ]])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                [step, step, guide, invest, share, market]\n",
       "1         [would, happen, indian, government, stole, koh...\n",
       "2                [internet, speed, increased, hacking, dns]\n",
       "3                    [find, remainder, math, math, divided]\n",
       "4                       [fish, would, survive, salt, water]\n",
       "                                ...                        \n",
       "404285    [many, keywords, perl, programming, language, ...\n",
       "404286                                  [true, life, death]\n",
       "404287                                        [whats, coin]\n",
       "404288    [little, hairfall, problem, want, use, hair, s...\n",
       "404289                                  [like, sex, cousin]\n",
       "Name: q2_words, Length: 404287, dtype: object"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df.q2_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.stop_words_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_q1 = vectorizer.transform(sample_df.question1)\n",
    "mat_q2 = vectorizer.transform(sample_df.question2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_mat = np.abs(mat_q1 - mat_q2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<404287x3000 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1594206 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404287, 1)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(jacc).reshape(-1, 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_mat = sparse.hstack([diff_mat, np.array(jacc).reshape(-1, 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = BernoulliNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB()"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.fit(trainX, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, testX, trainY, testY = train_test_split(diff_mat, sample_df.is_duplicate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/home/will/anaconda3/envs/scale-new/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.6s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(verbose=1)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(trainX, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "predY = lr.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "predY = nb.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7057246319455438"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(testY, predY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6545087061064713"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(testY, predY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.164074532997779"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(testY, predY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404287, 85846)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_q1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunks(lst, n):\n",
    "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
    "    for i in range(0, len(lst), n):\n",
    "        yield lst[i:i + n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "404287"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sample_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sample_df) // 5 / 2.42 / 60 / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_chunks = chunks(list(sample_df['question1']), 5)\n",
    "out = []\n",
    "for q1_chunk in tqdm(q1_chunks):\n",
    "    out.append(bmodel.encode(q1_chunk))\n",
    "# sample_df['bert2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df['q1_words'] = sample_df.question1.swifter.apply(clean_text)\n",
    "sample_df['q2_words'] = sample_df.question2.swifter.apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feats(words):\n",
    "    vecs = []\n",
    "    for word in words:\n",
    "        if word in model:\n",
    "            vecs.append(model[word]) # hopefully no overflow\n",
    "    if not vecs:\n",
    "        return np.nan\n",
    "    mat = np.vstack(vecs)\n",
    "    return mat.mean(axis=0)\n",
    "#     vec = np.zeros(300,)\n",
    "#     cnt = 0\n",
    "#     for word in words:\n",
    "#         if word in model:\n",
    "#             vec += model[word] # hopefully no overflow\n",
    "#             cnt += 1\n",
    "#     vec /= cnt # not always eql to len(words)\n",
    "#     return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df['q1_feats'] = sample_df.q1_words.swifter.apply(extract_feats)\n",
    "sample_df['q2_feats'] = sample_df.q2_words.swifter.apply(extract_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat_vector(a, b):\n",
    "    out = a - b\n",
    "#     out = np.hstack([a, b])\n",
    "    more = np.array([euclidean(a, b), cosine(a, b)])\n",
    "    return np.hstack([out, more])\n",
    "#     return more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_els1 = sample_df['q1_feats'].swifter.apply(lambda x: isinstance(x, np.ndarray) and not np.isnan(x).any())\n",
    "good_els2 = sample_df['q2_feats'].swifter.apply(lambda x: isinstance(x, np.ndarray) and not np.isnan(x).any())\n",
    "good_els = good_els1 & good_els2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_df = sample_df[good_els]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_df['diff'] = good_df.swifter.apply(lambda x: feat_vector(x['q1_feats'], x['q2_feats']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_df = good_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(verbose=1)\n",
    "rf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(good_df['diff'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(good_df.is_duplicate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.vstack(list(good_df['diff']))\n",
    "y = np.array(good_df.is_duplicate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_other, y_train, y_other = train_test_split(X, y, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, X_test, y_val, y_test = train_test_split(X_other, y_other, train_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = lgb.Dataset(X_train, label=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = lgb.Dataset(X_val, label=y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst = lgb.train({}, train_data, 100, valid_sets=[val_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = bst.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, thresholds = precision_recall_curve(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argsort(np.vstack([precision, recall]).sum(axis=0))[::-1][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_loss(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = np.arange(0, 1, 0.01)\n",
    "out = []\n",
    "for v in tqdm(vals):\n",
    "    out.append(f1_score(y_test, y_pred >= v))\n",
    "plt.plot(vals, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = np.arange(0, 1, 0.001)\n",
    "out = []\n",
    "for v in tqdm(vals):\n",
    "    out.append(accuracy_score(y_test, y_pred >= v))\n",
    "plt.plot(vals, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pred = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(rf_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(rf_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.predict(X_test).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.predict(X_train).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_df[sample_df.is_duplicate == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regexp_tokenize('I like to eat pie', pattern='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiny_df = sample_df.sample(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_bert = bmodel.encode(list(tiny_df.question1), show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q2_bert = bmodel.encode(list(tiny_df.question2), show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sX = q1_bert - q2_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sY = tiny_df.is_duplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Sx, test_Sx, train_sY, test_sY = train_test_split(sX, sY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiny_data = lgb.Dataset(train_Sx, label=train_sY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst = lgb.train({}, tiny_data, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_loss(test_sY, bst.predict(test_Sx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
